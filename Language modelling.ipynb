{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55073947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline,AutoTokenizer, AutoModel\n",
    "import random\n",
    "from morfeusz2 import Morfeusz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2384fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "morf = Morfeusz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb3781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584dd660",
   "metadata": {},
   "source": [
    "# Download three Polish models from the Huggingface repository. These should be regular language models, which were not fine-tuned. E.g. HerBERT and papuGaPT2 are good examples.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bc84d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "papuga = pipeline('text-generation', model='flax-community/papuGaPT2-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b9ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "herbert = pipeline(task=\"fill-mask\", model='allegro/herbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ba102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm = pipeline('fill-mask', model='facebook/xlm-v-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de38d14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "296785dcbf4e4b2d80177edc78237938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f392f10a77514884a268682232a40c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/557M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737c7b43c5a04d83982db3996a9118e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f920e9fb934417bcd8845eb3756aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/3.32M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27164ae5cec440a498930c0db51018bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bart = pipeline(\"fill-mask\", model=\"sdadas/polish-bart-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50be80c6",
   "metadata": {},
   "source": [
    "# Devise a method to test if the langage model understands Polish cases. E.g. testing for nominal case could be expressed as \"Warszawa to największe [MASK]\", and the masked word should be in nominative case. Create sentences for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0237d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_papuga='Wczoraj wieczorem poszedłem do <mask>.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "437c0997",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Wczoraj wieczorem poszedłem do <mask>. Na drugi dzień po prostu wybiegłam na zewnątrz i przeniosłam się na drugą stronę miasta (teraz już w zasadzie o tej samej porze). Przeniosłam się na drugą stronę, bo nie planowałam wejść na'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papuga(sentence_papuga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76ca00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence2=\"Warszawa to największe <mask>.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68176164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.893892765045166,\n",
       "  'token': 11381,\n",
       "  'token_str': 'miasto',\n",
       "  'sequence': 'Warszawa to największe miasto.'},\n",
       " {'score': 0.02109367586672306,\n",
       "  'token': 4122,\n",
       "  'token_str': 'miasta',\n",
       "  'sequence': 'Warszawa to największe miasta.'},\n",
       " {'score': 0.011969583109021187,\n",
       "  'token': 3610,\n",
       "  'token_str': 'centrum',\n",
       "  'sequence': 'Warszawa to największe centrum.'},\n",
       " {'score': 0.008560607209801674,\n",
       "  'token': 154945,\n",
       "  'token_str': 'lotnisko',\n",
       "  'sequence': 'Warszawa to największe lotnisko.'},\n",
       " {'score': 0.005978821311146021,\n",
       "  'token': 2104,\n",
       "  'token_str': 'miejsce',\n",
       "  'sequence': 'Warszawa to największe miejsce.'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1ce10a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.8103944063186646,\n",
       "  'token': 4618,\n",
       "  'token_str': 'miasto',\n",
       "  'sequence': 'Warszawa to największe miasto.'},\n",
       " {'score': 0.082491934299469,\n",
       "  'token': 23562,\n",
       "  'token_str': 'lotnisko',\n",
       "  'sequence': 'Warszawa to największe lotnisko.'},\n",
       " {'score': 0.0265207439661026,\n",
       "  'token': 4831,\n",
       "  'token_str': 'centrum',\n",
       "  'sequence': 'Warszawa to największe centrum.'},\n",
       " {'score': 0.01798691414296627,\n",
       "  'token': 3073,\n",
       "  'token_str': 'miasta',\n",
       "  'sequence': 'Warszawa to największe miasta.'},\n",
       " {'score': 0.005562868434935808,\n",
       "  'token': 21445,\n",
       "  'token_str': 'atrakcje',\n",
       "  'sequence': 'Warszawa to największe atrakcje.'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "herbert(sentence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "842e7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correctness(word):\n",
    "    return set([z\n",
    "                    for x in morf.analyse(word)\n",
    "                    if x[2][2].split(':')[0] == 'subst'\n",
    "                    for z in x[2][2].split(':')[2].split('.')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cd60ab71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc', 'nom', 'voc'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_correctness('mleko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "075bb4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_test = {\n",
    "    'mianownik': ('Bartek poszedł kupić <mask>.', 'nom', 'mleko'),\n",
    "    'dopełniacz': ('Basia nie kupiła <mask>.', 'gen', 'mleka'),\n",
    "    'celownik': ('Uczeń przygląda się pani <mask>.', 'dat', 'nauczycielce'),\n",
    "    'biernik': ('Mama gotuje <mask>.', 'acc', 'obiad'),\n",
    "    'narzędnik': ('Natalia interesuje się <mask>.', 'inst', 'malarstwem'),\n",
    "    'miejscownik': ('Myślę o wczorajszym <mask> i ciągle mam na niego ochotę.', 'loc', 'deserze'),\n",
    "    'wołacz': ('Przybywasz za późno, <mask>.', 'voc', 'bohaterze')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fcdf3fc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "('Bartek poszedł kupić <mask>.', 'nom', 'mleko')\n",
      "#########\n",
      "Bartek poszedł kupić buty.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić rower.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić telewizor.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić książki.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić książkę.\n",
      "===============================================\n",
      "#########\n",
      "('Basia nie kupiła <mask>.', 'gen', 'mleka')\n",
      "#########\n",
      "Basia nie kupiła książki.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła samochodu.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła mieszkania.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła auta.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła butów.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Uczeń przygląda się pani <mask>.', 'dat', 'nauczycielce')\n",
      "#########\n",
      "Uczeń przygląda się pani dyrektor.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani doktor.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani profesor.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani domu.\n",
      "Uczeń przygląda się pani Dyrektor.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Mama gotuje <mask>.', 'acc', 'obiad')\n",
      "#########\n",
      "Mama gotuje obiad.\n",
      "correct form\n",
      "--------\n",
      "Mama gotuje zupę.\n",
      "correct form\n",
      "--------\n",
      "Mama gotuje ciasto.\n",
      "correct form\n",
      "--------\n",
      "Mama gotuje śniadanie.\n",
      "correct form\n",
      "--------\n",
      "Mama gotuje chleb.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Natalia interesuje się <mask>.', 'inst', 'malarstwem')\n",
      "#########\n",
      "Natalia interesuje się sportem.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się muzyką.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się polityką.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się teatrem.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się handlem.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Myślę o wczorajszym <mask> i ciągle mam na niego ochotę.', 'loc', 'deserze')\n",
      "#########\n",
      "Myślę o wczorajszym obiedzie i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym koncercie i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym spotkaniu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym meczu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym filmie i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Przybywasz za późno, <mask>.', 'voc', 'bohaterze')\n",
      "#########\n",
      "Przybywasz za późno, stary.\n",
      "correct form\n",
      "--------\n",
      "Przybywasz za późno, młody.\n",
      "correct form\n",
      "--------\n",
      "Przybywasz za późno, sir.\n",
      "Przybywasz za późno, proszę.\n",
      "Przybywasz za późno, panowie.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "Result: 85/35\n"
     ]
    }
   ],
   "source": [
    "points_herb=0\n",
    "for text in polish_test:\n",
    "    print(\"#########\")\n",
    "    print(polish_test[text])\n",
    "    print(\"#########\")\n",
    "    expected=polish_test[text][1]\n",
    "    pred=herbert(polish_test[text][0])\n",
    "    for sentence in pred:\n",
    "        print(sentence['sequence'])\n",
    "        if expected in analyze_correctness(sentence['token_str']):\n",
    "            print('correct form')\n",
    "            print(\"--------\")\n",
    "            points_herb+=1\n",
    "\n",
    "    print(\"===============================================\")\n",
    "\n",
    "print(f\"Result: {points_herb}/35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "204049f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "('Bartek poszedł kupić <mask>.', 'nom', 'mleko')\n",
      "#########\n",
      "Bartek poszedł kupić piwo.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić książkę.\n",
      "Bartek poszedł kupić prezenty.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić śniadanie.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić wino.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Basia nie kupiła <mask>.', 'gen', 'mleka')\n",
      "#########\n",
      "Basia nie kupiła mnie.\n",
      "Basia nie kupiła..\n",
      "Basia nie kupiła nic.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła sie.\n",
      "Basia nie kupiła....\n",
      "===============================================\n",
      "#########\n",
      "('Uczeń przygląda się pani <mask>.', 'dat', 'nauczycielce')\n",
      "#########\n",
      "Uczeń przygląda się panii.\n",
      "Uczeń przygląda się paniom.\n",
      "Uczeń przygląda się pani..\n",
      "Uczeń przygląda się pani domu.\n",
      "Uczeń przygląda się panią.\n",
      "===============================================\n",
      "#########\n",
      "('Mama gotuje <mask>.', 'acc', 'obiad')\n",
      "#########\n",
      "Mama gotuje..\n",
      "Mama gotuje:.\n",
      "Mama gotuje :.\n",
      "Mama gotuje,.\n",
      "Mama gotuje....\n",
      "===============================================\n",
      "#########\n",
      "('Natalia interesuje się <mask>.', 'inst', 'malarstwem')\n",
      "#########\n",
      "Natalia interesuje się muzyką.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się dziećmi.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się książką.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się historią.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się światem.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Myślę o wczorajszym <mask> i ciągle mam na niego ochotę.', 'loc', 'deserze')\n",
      "#########\n",
      "Myślę o wczorajszym posiłku i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym spektaklu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym filmie i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym spotkaniu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym dniu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Przybywasz za późno, <mask>.', 'voc', 'bohaterze')\n",
      "#########\n",
      "Przybywasz za późno,.\n",
      "Przybywasz za późno, o.\n",
      "Przybywasz za późno,..\n",
      "Przybywasz za późno, panie.\n",
      "correct form\n",
      "--------\n",
      "Przybywasz za późno,....\n",
      "===============================================\n",
      "Result: 85/35\n"
     ]
    }
   ],
   "source": [
    "points_xlm=0\n",
    "for text in polish_test:\n",
    "    print(\"#########\")\n",
    "    print(polish_test[text])\n",
    "    print(\"#########\")\n",
    "    expected=polish_test[text][1]\n",
    "    pred=xlm(polish_test[text][0])\n",
    "    for sentence in pred:\n",
    "        print(sentence['sequence'])\n",
    "#         print(get_predicted_declension(sentence['token_str']))\n",
    "        if expected in get_predicted_declension(sentence['token_str']):\n",
    "            print('correct form')\n",
    "            print(\"--------\")\n",
    "            points_xlm+=1\n",
    "\n",
    "    print(\"===============================================\")\n",
    "\n",
    "print(f\"Result: {points_xlm}/35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "333d8938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########\n",
      "('Bartek poszedł kupić <mask>.', 'nom', 'mleko')\n",
      "#########\n",
      "Bartek poszedł kupić sobie.\n",
      "Bartek poszedł kupić mu.\n",
      "Bartek poszedł kupić coś.\n",
      "correct form\n",
      "--------\n",
      "Bartek poszedł kupić książkę.\n",
      "Bartek poszedł kupić bilet.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Basia nie kupiła <mask>.', 'gen', 'mleka')\n",
      "#########\n",
      "Basia nie kupiła jeszcze.\n",
      "Basia nie kupiła sobie.\n",
      "Basia nie kupiła biletów.\n",
      "correct form\n",
      "--------\n",
      "Basia nie kupiła już.\n",
      "Basia nie kupiła mieszkania.\n",
      "correct form\n",
      "--------\n",
      "===============================================\n",
      "#########\n",
      "('Uczeń przygląda się pani <mask>.', 'dat', 'nauczycielce')\n",
      "#########\n",
      "Uczeń przygląda się panice.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani doktor.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani profesor.\n",
      "correct form\n",
      "--------\n",
      "Uczeń przygląda się pani z.\n",
      "Uczeń przygląda się pani w.\n",
      "===============================================\n",
      "#########\n",
      "('Mama gotuje <mask>.', 'acc', 'obiad')\n",
      "#########\n",
      "Mama gotuje..\n",
      "Mama gotuje dla.\n",
      "Mama gotuje i.\n",
      "Mama gotuje z.\n",
      "Mama gotuje,.\n",
      "===============================================\n",
      "#########\n",
      "('Natalia interesuje się <mask>.', 'inst', 'malarstwem')\n",
      "#########\n",
      "Natalia interesuje się również.\n",
      "Natalia interesuje się także.\n",
      "Natalia interesuje się też.\n",
      "Natalia interesuje się muzyką.\n",
      "correct form\n",
      "--------\n",
      "Natalia interesuje się spor.\n",
      "===============================================\n",
      "#########\n",
      "('Myślę o wczorajszym <mask> i ciągle mam na niego ochotę.', 'loc', 'deserze')\n",
      "#########\n",
      "Myślę o wczorajszym wieczo i ciągle mam na niego ochotę.\n",
      "Myślę o wczorajszym śniadaniu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym filmie i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym spotkaniu i ciągle mam na niego ochotę.\n",
      "correct form\n",
      "--------\n",
      "Myślę o wczorajszym, i ciągle mam na niego ochotę.\n",
      "===============================================\n",
      "#########\n",
      "('Przybywasz za późno, <mask>.', 'voc', 'bohaterze')\n",
      "#########\n",
      "Przybywasz za późno, by.\n",
      "Przybywasz za późno, aby.\n",
      "Przybywasz za późno, żeby.\n",
      "Przybywasz za późno, a.\n",
      "Przybywasz za późno, bo.\n",
      "===============================================\n",
      "Result: 85/35\n"
     ]
    }
   ],
   "source": [
    "points_bart=0\n",
    "for text in polish_test:\n",
    "    print(\"#########\")\n",
    "    print(polish_test[text])\n",
    "    print(\"#########\")\n",
    "    expected=polish_test[text][1]\n",
    "    pred=bart(polish_test[text][0])\n",
    "    for sentence in pred:\n",
    "        print(sentence['sequence'])\n",
    "#         print(get_predicted_declension(sentence['token_str']))\n",
    "        if expected in get_predicted_declension(sentence['token_str']):\n",
    "            print('correct form')\n",
    "            print(\"--------\")\n",
    "            points_bart+=1\n",
    "\n",
    "    print(\"===============================================\")\n",
    "\n",
    "print(f\"Result: {points_bart}/35\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a9bc9861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_results:\n",
      "herbert: 31/35\n",
      "xlm: 16/35\n",
      "bart: 11/35\n"
     ]
    }
   ],
   "source": [
    "print(f\"final_results:\\nherbert: {points_herb}/35\\nxlm: {points_xlm}/35\\nbart: {points_bart}/35\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ea01a4",
   "metadata": {},
   "source": [
    "Despite results, these models are able to recognize correct word to fill the mask. In most cases, proposed words make sense, but in model xlm in shorter sentences, proposed examples sometimes are not matching expected result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da9a43",
   "metadata": {},
   "source": [
    "# Devise a method to test long-range relationships such as gender. E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "f6b1fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "fill_sentence = lambda model, sentence: re.sub(\"<mask>\", model(sentence)[0]['token_str'], sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c3486c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1=\"Nauczycielka <mask> swoich uczniów i nie chciała sie z nimi rozstawać.\"\n",
    "example_2=\"Lekarka poznała mężczyznę, więc <mask> by się z nim zobaczyć\"\n",
    "example_3='Architekt uwielbiał swoją pracę, ale mimo to <mask> ją opuścić.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b4f64bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nauczycielka bardzo swoich uczniów i nie chciała sie z nimi rozstawać.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "21ca262a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nauczycielka lubiła swoich uczniów i nie chciała sie z nimi rozstawać.'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9c6457b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nauczycielka kocha swoich uczniów i nie chciała sie z nimi rozstawać.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3e13fe22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lekarka poznała mężczyznę, więc nie by się z nim zobaczyć'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b4ec55f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lekarka poznała mężczyznę, więc przyszła by się z nim zobaczyć'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "0e4d6839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lekarka poznała mężczyznę, więc chciała by się z nim zobaczyć'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "814c9b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architekt uwielbiał swoją pracę, ale mimo to nie ją opuścić.'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "331249c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architekt uwielbiał swoją pracę, ale mimo to musiał ją opuścić.'"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ad89893d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Architekt uwielbiał swoją pracę, ale mimo to postanowił ją opuścić.'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6293b59",
   "metadata": {},
   "source": [
    "# Check if the model captures real-world knolwedge. For instance a sentence \"[MASK] wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "47fa86b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_r_w_knowledge_1=\"<mask> wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\"\n",
    "example_r_w_knowledge_2=\"<mask>, czyli jedna z planet Układu Słonecznego, trzecia od Słońca; jest znana z bogactwa różnorodnych form życia.\"\n",
    "example_r_w_knowledge_3=\"<mask> czyli proces, podczas którego substancje zmieniają się z ciekłego stanu w gazowy bez bezpośredniego przechodzenia przez stan stały.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "09e575f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_r_w_knowledge_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2df68527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_r_w_knowledge_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fa5963f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Woda wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_r_w_knowledge_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "35e59775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plane, czyli jedna z planet Układu Słonecznego, trzecia od Słońca; jest znana z bogactwa różnorodnych form życia.'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_r_w_knowledge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ef5acf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wenus, czyli jedna z planet Układu Słonecznego, trzecia od Słońca; jest znana z bogactwa różnorodnych form życia.'"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_r_w_knowledge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a7d1fb57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pluto, czyli jedna z planet Układu Słonecznego, trzecia od Słońca; jest znana z bogactwa różnorodnych form życia.'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_r_w_knowledge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f60608be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gaz czyli proces, podczas którego substancje zmieniają się z ciekłego stanu w gazowy bez bezpośredniego przechodzenia przez stan stały.'"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(bart,example_r_w_knowledge_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c5c35766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jest czyli proces, podczas którego substancje zmieniają się z ciekłego stanu w gazowy bez bezpośredniego przechodzenia przez stan stały.'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(herbert,example_r_w_knowledge_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f8fe64e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s> czyli proces, podczas którego substancje zmieniają się z ciekłego stanu w gazowy bez bezpośredniego przechodzenia przez stan stały.'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_sentence(xlm,example_r_w_knowledge_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14589137",
   "metadata": {},
   "source": [
    "# Check zero-shot learning capabilites of the models. Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie [MASK]\" Try different prompts, to see if they make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "bf3eb25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rev1=\"'Ta książka to była rewelacja. Nie mogłem się oderwać od kolejnych stron.'\"\n",
    "rev2=\"'To miasto to jest koszmar. Nie mogłem się oderwać od myśli o jego chaotycznej strukturze.'\"\n",
    "rev3=\"'Ten koncert to była niesamowita uczta muzyczna. Nie mogłem się oderwać od dźwięków.'\"\n",
    "rev4=\"'Ta restauracja to była kulinarna rozczarowanie. Nie mogłem się oderwać od myśli o smaku jedzenia.'\"\n",
    "rev5=\"'Ten serial to był emocjonalny rollercoaster. Nie mogłem się oderwać od oglądania kolejnych odcinków.'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f3186ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans1=\" Wypowiedź ta jest zdecydowanie <mask>.\"\n",
    "ans2=\" Oceny tego mogą być różne, dla mnie było to <mask>.\"\n",
    "ans3=\" Poprzednia wypowiedź ma charakter <mask>.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "634cd3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "review 1\n",
      "\n",
      "================================\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: prawdziwa\n",
      "prompt: 0, model: xlm       opinion: najlepsza\n",
      "prompt: 0, model: bart      opinion: warta\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: zaskoczenie\n",
      "prompt: 0, model: xlm       opinion: 10/10\n",
      "prompt: 0, model: bart      opinion: coś\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: krytyczny\n",
      "prompt: 0, model: xlm       opinion: pozytywny\n",
      "prompt: 0, model: bart      opinion: wyłącznie\n",
      "\n",
      "review 2\n",
      "\n",
      "================================\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: prawdziwa\n",
      "prompt: 0, model: xlm       opinion: zła\n",
      "prompt: 0, model: bart      opinion: zbyt\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: straszne\n",
      "prompt: 0, model: xlm       opinion: koszmar\n",
      "prompt: 0, model: bart      opinion: coś\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: krytyczny\n",
      "prompt: 0, model: xlm       opinion: historyczny\n",
      "prompt: 0, model: bart      opinion: wyłącznie\n",
      "\n",
      "review 3\n",
      "\n",
      "================================\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: prawdziwa\n",
      "prompt: 0, model: xlm       opinion: najlepsza\n",
      "prompt: 0, model: bart      opinion: godna\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: niesamowite\n",
      "prompt: 0, model: xlm       opinion: wyjątkowe\n",
      "prompt: 0, model: bart      opinion: coś\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: informacyjny\n",
      "prompt: 0, model: xlm       opinion: historyczny\n",
      "prompt: 0, model: bart      opinion: wyłącznie\n",
      "\n",
      "review 4\n",
      "\n",
      "================================\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: prawdziwa\n",
      "prompt: 0, model: xlm       opinion: najlepsza\n",
      "prompt: 0, model: bart      opinion: dla\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: niesamowite\n",
      "prompt: 0, model: xlm       opinion: niesamowite\n",
      "prompt: 0, model: bart      opinion: coś\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: krytyczny\n",
      "prompt: 0, model: xlm       opinion: informacyjny\n",
      "prompt: 0, model: bart      opinion: wyłącznie\n",
      "\n",
      "review 5\n",
      "\n",
      "================================\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: prawdziwa\n",
      "prompt: 0, model: xlm       opinion: najlepsza\n",
      "prompt: 0, model: bart      opinion: godna\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: niesamowite\n",
      "prompt: 0, model: xlm       opinion: przeżycie\n",
      "prompt: 0, model: bart      opinion: coś\n",
      "-----\n",
      "prompt: 0, model: herbert,  opinion: krytyczny\n",
      "prompt: 0, model: xlm       opinion: historyczny\n",
      "prompt: 0, model: bart      opinion: wyłącznie\n"
     ]
    }
   ],
   "source": [
    "r=0\n",
    "for x in [rev1,rev2,rev3,rev4,rev5]:\n",
    "    r+=1\n",
    "    print(f'\\nreview {r}\\n')\n",
    "    p=0\n",
    "    print(\"================================\")\n",
    "    for y in [ans1,ans2,ans3]:\n",
    "        print('-----')\n",
    "        print(f'prompt: {p}'  + ', model: herbert,  opinion: '+ herbert(x+y)[0]['token_str'])\n",
    "        print(f'prompt: {p}'  + ', model: xlm       opinion: ' + xlm(x+y)[0]['token_str'])\n",
    "        print(f'prompt: {p}'  + ', model: bart      opinion: '+ bart(x+y)[0]['token_str'])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fc43a3",
   "metadata": {},
   "source": [
    "# Answer the following questions (2 points):\n",
    "\n",
    "- Which of the models produced the best results?\n",
    "\n",
    "Overall the best results were produced by herbert model. He has the most accurate answers when it comes to testing for nominal case. Also model xlm had very good results testing zero-shot learning capabilites. BART model had the worst results, it couldn't even guess word \"WODA\" in real-world knolwedge sentence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c72354",
   "metadata": {},
   "source": [
    "- Was any of the models able to capture Polish grammar?\n",
    "\n",
    "As i was saying in the previous question, herbert was the most succesful. Other languages also did good, but not as well as herbert. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e5a465",
   "metadata": {},
   "source": [
    "- Was any of the models able to capture long-distant relationships between the words?\n",
    "\n",
    "\n",
    "herBERT and xlm did very well, they correctly replaced masks, model BERT wasn't so fortunate, it coulnd't guess matching verb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889c7ac",
   "metadata": {},
   "source": [
    "- Was any of the models able to capture world knowledge?\n",
    "\n",
    "It was hard task for all models. At least when it came to the second question, herBERT and XLM tried to guess planet name. Model bert couldn't handle this task either."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c55380",
   "metadata": {},
   "source": [
    "- Was any of the models good at doing zero-shot classification?\n",
    "\n",
    "The best job did XLM model. Answers of this model were definitely the most various, in most cases correct. Second best was herBert, which did quite good job guessing the nature of the statement. BERT's answers were mostly without context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c86cb",
   "metadata": {},
   "source": [
    "- What are the most striking errors made by the models?\n",
    "\n",
    "\n",
    "Generating random words by BERT, maybe in the first task, if we gave him possibility to generate more words in one blank, then the results would be better.\n",
    "\n",
    "XLM couldn't handle simple sentences, for example: Basia nie kupiła <mask>. Results speak for themselves.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932100a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
