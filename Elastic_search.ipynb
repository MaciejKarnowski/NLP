{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "739b211f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '65db7b99f9bf',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'oMd2u2xuSBugp0oySEszgw',\n",
       " 'version': {'number': '8.10.4',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': 'b4a62ac808e886ff032700c391f45f1408b2538c',\n",
       "  'build_date': '2023-10-11T22:04:35.506990650Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '9.7.0',\n",
       "  'minimum_wire_compatibility_version': '7.17.0',\n",
       "  'minimum_index_compatibility_version': '7.0.0'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "es = Elasticsearch(['http://localhost:9200/'])\n",
    "\n",
    "es.info().body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf6125b",
   "metadata": {},
   "source": [
    "## 3,4 Define an ES analyzer for Polish texts. Define another analyzer for Polish, without the synonym filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "96ff426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings= {\n",
    "  \"analysis\": {\n",
    "    \"analyzer\": {\n",
    "      \"analyzer_with_synonym\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"filter\": [\n",
    "          \"synonyms_filter\",\n",
    "          \"lowercase\",\n",
    "          \"morfologik_stem\",\n",
    "          \"lowercase\"\n",
    "        ]\n",
    "      },\n",
    "      \"analyzer_without_synonym\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"filter\": [\n",
    "          \"lowercase\",\n",
    "          \"morfologik_stem\",\n",
    "          \"lowercase\"\n",
    "        ]\n",
    "      },\n",
    "      \"analyzer_without_lematization\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"filter\": [\n",
    "          \"synonyms_filter\",\n",
    "          \"lowercase\"\n",
    "        ]\n",
    "      },\n",
    "      \"analyzer_without_synonym_and_lematization\": {\n",
    "        \"type\": \"custom\",\n",
    "        \"tokenizer\": \"standard\",\n",
    "        \"filter\": [\n",
    "          \"lowercase\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    \"filter\": {\n",
    "     \"synonyms_filter\": {\n",
    "                \"type\": \"synonym\",\n",
    "                \"synonyms\": [\n",
    "            \"styczeń, sty, I\",\n",
    "            \"luty, lut, II\",\n",
    "            \"marzec, mar, III\",\n",
    "            \"kwiecień, kwi, IV\",\n",
    "            \"maj, V\",\n",
    "            \"czerwiec, cze, VI\",\n",
    "            \"lipiec, lip, VII\",\n",
    "            \"sierpień, sie, VIII\",\n",
    "            \"wrzesień, wrz, IX\",\n",
    "            \"październik, paź, X\",\n",
    "            \"listopad, lis, XI\",\n",
    "            \"grudzień, gru, XII\"\n",
    "          ]\n",
    "        }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046b91ab",
   "metadata": {},
   "source": [
    "## 5 Define an ES index for storing the contents of the corpus from lab 1 using both analyzers. Use different names for the fields analyzed with a different pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d16aef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_NAME1 = \"analyzer_with_synonym\"\n",
    "INDEX_NAME2 = \"analyzer_without_synonym\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a6b244c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.delete(index=INDEX_NAME1)\n",
    "es.indices.delete(index=INDEX_NAME2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cf56bd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'analyzer_without_synonym'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.indices.create(index=INDEX_NAME1, settings=settings)\n",
    "es.indices.create(index=INDEX_NAME2, settings=settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd074790",
   "metadata": {},
   "source": [
    "## 6 Load the data to the ES index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "da903839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fiqa-pl (C:/Users/Macie/.cache/huggingface/datasets/clarin-knext___fiqa-pl/corpus/0.0.0/bada00640881ee3fd04c3b88df9edd435616d17e0a46faf05e63063858742140)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a59dfc5996b547edb20c64638259fa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    corpus: Dataset({\n",
       "        features: ['_id', 'title', 'text'],\n",
       "        num_rows: 57638\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d24069ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td></td>\n",
       "      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57633</th>\n",
       "      <td>599946</td>\n",
       "      <td></td>\n",
       "      <td>&gt;Cóż, po pierwsze, drogi to coś więcej niż hob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57634</th>\n",
       "      <td>599953</td>\n",
       "      <td></td>\n",
       "      <td>Tak, robią. Na dotacje dla firm farmaceutyczny...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57635</th>\n",
       "      <td>599966</td>\n",
       "      <td></td>\n",
       "      <td>&gt;To bardzo smutne, że nie rozumiesz ludzkiej n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57636</th>\n",
       "      <td>599975</td>\n",
       "      <td></td>\n",
       "      <td>„Czy Twój CTO pozwolił dużej grupie użyć „„adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57637</th>\n",
       "      <td>599987</td>\n",
       "      <td></td>\n",
       "      <td>Zapewnienie rządowi większej kontroli nad dyst...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57638 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          _id title                                               text\n",
       "0           3        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1          31        Tak więc nic nie zapobiega fałszywym ocenom po...\n",
       "2          56        Nigdy nie możesz korzystać z FSA dla indywidua...\n",
       "3          59        Samsung stworzył LCD i inne technologie płaski...\n",
       "4          63        Oto wymagania SEC: Federalne przepisy dotycząc...\n",
       "...       ...   ...                                                ...\n",
       "57633  599946        >Cóż, po pierwsze, drogi to coś więcej niż hob...\n",
       "57634  599953        Tak, robią. Na dotacje dla firm farmaceutyczny...\n",
       "57635  599966        >To bardzo smutne, że nie rozumiesz ludzkiej n...\n",
       "57636  599975        „Czy Twój CTO pozwolił dużej grupie użyć „„adm...\n",
       "57637  599987        Zapewnienie rządowi większej kontroli nad dyst...\n",
       "\n",
       "[57638 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(dataset['corpus'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d39f5dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c23419a9fef4171913025e9a363389b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "body = list(itertools.chain(*df.apply(lambda x: ({'index': {'_id': x._id}}, {'title': x.title, 'text': x.text}) , axis=1)))\n",
    "chunk_size = 200\n",
    "for chunk in tqdm([body[i:i + chunk_size] for i in range(0, len(body), chunk_size)]):\n",
    "    es.bulk(\n",
    "        index=INDEX_NAME1,\n",
    "        body=chunk\n",
    "    )\n",
    "    es.bulk(\n",
    "        index=INDEX_NAME2,\n",
    "        body=chunk\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9d79993b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57638\n",
      "57638\n"
     ]
    }
   ],
   "source": [
    "print(es.count(index=INDEX_NAME1)['count'])\n",
    "print(es.count(index=INDEX_NAME2)['count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07313f73",
   "metadata": {},
   "source": [
    "## 7 Determine the number of documents containing the word styczeń (in any form) including and excluding the synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "542c1619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44123"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=INDEX_NAME1,  analyzer='analyzer_with_synonym', q='text:styczeń')['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54251bef",
   "metadata": {},
   "source": [
    "Count of word 'styczeń' with synonymes is not reliable. Possible that elastic search takes wrong synonymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "844e4272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.count(index=INDEX_NAME2,  analyzer='analyzer_without_synonym', q='text:styczeń')['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1669ed34",
   "metadata": {},
   "source": [
    "## 8 Download the QA pairs for the FIQA dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb03842e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95cb6653953d409eac0bdcbcaf9b1944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/clarin-knext--fiqa-pl-qrels to C:/Users/Macie/.cache/huggingface/datasets/clarin-knext___csv/clarin-knext--fiqa-pl-qrels-87c7ba66b4612e3c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0791bbc1c46843ae8e89ebeb71136252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6446e1048f1c49bab59f94cda496c08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/210k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f0a8267fd04b0dbaaee6019680a15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/18.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df822bac6ce94cbebf3303cefdbb13c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/25.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848123189f8e4b9687dbc1f36fea41fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Macie/.cache/huggingface/datasets/clarin-knext___csv/clarin-knext--fiqa-pl-qrels-87c7ba66b4612e3c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560f00575220414593d9c32bdb929544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "QA_dataset = load_dataset(\"clarin-knext/fiqa-pl-qrels\", 'corpus')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a05c1e",
   "metadata": {},
   "source": [
    "## What are the strengths and weaknesses of regular expressions versus full text search regarding processing of text?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4790867b",
   "metadata": {},
   "source": [
    "The biggest advantage of regular search is how quickly we get acquainted with it. It is easy to use and very useful for smaller natural language processing tasks. In contrast, using elastic search is much more complicated. From installation problems to very extensive usage options. Without a doubt, it is a better tool when you want to solve very complex natural processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3e126",
   "metadata": {},
   "source": [
    "## Is full text search applicable to the question answering problem? show at least 3 examples from the corpus to support your claim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eab34e9",
   "metadata": {},
   "source": [
    "Full search can be applicable to the question answering problem. It should be noted that it searches out of context, so some of the results may not be what u are looking for.\n",
    "usage examples:\n",
    "- FAQs\n",
    "- Legal Documents\n",
    "- Medical Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bb454c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
